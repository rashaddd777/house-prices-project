{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 1 - Import Libraries & Setup Paths\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Append project root if needed\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Define directories for outputs\n",
    "figures_dir = \"../reports/figures\"\n",
    "text_dir = \"../reports/text\"\n",
    "processed_dir = \"../data/processed\"\n",
    "raw_dir = \"../data/raw\"\n",
    "\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "os.makedirs(text_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully.\n"
     ]
    }
   ],
   "source": [
    "#Cell 2 - Import Preprocessing & Feature Engineering Functions and Model Loading\n",
    "\n",
    "from src.data_preprocessing import impute_missing_values  # if needed\n",
    "from src.feature_engineering import engineer_features, encode_categorical\n",
    "from src.models import load_model\n",
    "\n",
    "print(\"Modules imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model loaded from: ../data/processed/ensemble_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#Cell 3 - Load Final Ensemble Model\n",
    "\n",
    "ensemble_model_path = os.path.join(processed_dir, \"ensemble_model.pkl\")\n",
    "ensemble_model = load_model(ensemble_model_path)\n",
    "print(\"Ensemble model loaded from:\", ensemble_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded. Shape: (1459, 80)\n",
      "Test data processed. Shape after feature engineering and encoding: (1459, 111)\n"
     ]
    }
   ],
   "source": [
    "#Cell 4 - Load and Process Test Data\n",
    "# Load the test dataset (assumed to be in raw directory)\n",
    "\n",
    "test_data_path = os.path.join(raw_dir, \"test.csv\")\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "print(\"Test data loaded. Shape:\", df_test.shape)\n",
    "\n",
    "# Preserve the 'Id' column for submission\n",
    "ids = df_test['Id']\n",
    "\n",
    "# Apply missing value imputation if needed (using similar logic as training)\n",
    "df_test = impute_missing_values(df_test)\n",
    "\n",
    "# Apply feature engineering using our module\n",
    "df_test = engineer_features(df_test)\n",
    "\n",
    "# Optionally, encode categorical features (using same columns as training)\n",
    "# Adjust the list of categorical columns based on training.\n",
    "cat_cols = ['MSZoning', 'Neighborhood']  # Example; adjust as needed.\n",
    "df_test_encoded = encode_categorical(df_test, cat_cols=cat_cols)\n",
    "\n",
    "print(\"Test data processed. Shape after feature engineering and encoding:\", df_test_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared test features shape: (1459, 69)\n"
     ]
    }
   ],
   "source": [
    "#Cell 5 - Prepare Features for Prediction\n",
    "# In training we used numeric columns only, so select those columns.\n",
    "# Drop 'Id' from features if present.\n",
    "\n",
    "numeric_test = df_test_encoded.select_dtypes(include=['number'])\n",
    "if 'Id' in numeric_test.columns:\n",
    "    numeric_test = numeric_test.drop(columns=['Id'])\n",
    "\n",
    "# For prediction, ensure the features match those used in training.\n",
    "# (This assumes that your training pipeline produced consistent columns.)\n",
    "X_test = numeric_test\n",
    "print(\"Prepared test features shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to: ../data/processed/submission.csv\n"
     ]
    }
   ],
   "source": [
    "#Cell 6 - Generate Predictions & Create Submission File\n",
    "# Generate predictions using the loaded ensemble model\n",
    "\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Create a submission DataFrame with Id and SalePrice\n",
    "submission = pd.DataFrame({\n",
    "    'Id': ids,\n",
    "    'SalePrice': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the submission file to processed folder\n",
    "submission_path = os.path.join(processed_dir, \"submission.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(\"Submission file saved to:\", submission_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>128691.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>158538.327457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>184800.778271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>185981.785912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>199741.577749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  128691.431700\n",
       "1  1462  158538.327457\n",
       "2  1463  184800.778271\n",
       "3  1464  185981.785912\n",
       "4  1465  199741.577749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 7 - Optional: Display Submission Sample\n",
    "\n",
    "display(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
